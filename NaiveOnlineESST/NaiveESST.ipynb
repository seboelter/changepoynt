{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "from functools import partial\n",
    "from changepoynt.algorithms.base_algorithm import Algorithm\n",
    "from changepoynt.utils import normalization\n",
    "from changepoynt.utils import linalg as lg\n",
    "import fbpca\n",
    "import multiprocessing as mp\n",
    "import numba as nb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_entropy(hankel: np.ndarray, rank: int, random_rank: int, method: str, threads: int) -> float:\n",
    "    \"\"\"\n",
    "    Entropy Singular Spectrum Transformation.\n",
    "\n",
    "    :param hankel: the hankel matrix of the signal\n",
    "    :param rank: the number of (approximated) eigenvectors as subspace of H1\n",
    "    :param random_rank: the sampling parameter for the randomized svd\n",
    "    :param method: which rsvd method to use\n",
    "    :param threads: the numba of threads numba is allowed to use\n",
    "    :return: the change point score, the input vector x0\n",
    "    \"\"\"\n",
    "    # compute the left and right eigenvectors using the randomized svd for fast computation\n",
    "    threads_before = nb.get_num_threads()\n",
    "    nb.set_num_threads(threads)\n",
    "    if method == 'fbrsvd':\n",
    "        right_eigenvectors, eigenvalues, left_eigenvectors = fbpca.pca(hankel, rank, True)\n",
    "    elif method == 'rsvd':\n",
    "        right_eigenvectors, eigenvalues, left_eigenvectors = lg.randomized_hankel_svd(hankel, rank,\n",
    "                                                                                      oversampling_p=random_rank - rank)\n",
    "    else:\n",
    "        raise NotImplementedError(f'Method {method} is not available.')\n",
    "    nb.set_num_threads(threads_before)\n",
    "\n",
    "    # shift the left eigenvectors up\n",
    "    left_eigenvectors = left_eigenvectors - np.min(left_eigenvectors, axis=1)[:, None] + 1\n",
    "\n",
    "    # make the eigenvectors into \"probability distributions\" so their sum of elements is one\n",
    "    left_eigenvectors = left_eigenvectors/np.sum(left_eigenvectors, axis=1)[:, None]\n",
    "\n",
    "    # compute the normalized entropy of the eigenvectors\n",
    "    \"\"\"entropy = (-1 *\n",
    "               np.sum(np.log2(left_eigenvectors, out=np.zeros_like(left_eigenvectors), where=(left_eigenvectors != 0))\n",
    "                      * left_eigenvectors, axis=1))/np.log2(hankel.shape[1])\"\"\"\n",
    "    # skew = np.abs(skewness(left_eigenvectors, np.tile(np.linspace(0, hankel.shape[1]-1, hankel.shape[1]), (rank, 1))))\n",
    "    skew = np.abs(left_right_diff(left_eigenvectors))\n",
    "\n",
    "    # compute the weighted mean of the entropy\n",
    "    # weighted_entropy = (eigenvalues @ ((1-entropy)*skew))/np.sum(eigenvalues)\n",
    "    weighted_entropy = (eigenvalues @ skew) / np.sum(eigenvalues)\n",
    "\n",
    "    return weighted_entropy\n",
    "\n",
    "def left_right_diff(left_eigenvectors: np.ndarray):\n",
    "    n = left_eigenvectors.shape[1]//2\n",
    "    return np.mean(left_eigenvectors[:, :n]-left_eigenvectors[:, n:], axis=1)\n",
    "\n",
    "    # some plotting utilities\n",
    "def plot_data_and_score(raw_data, score):\n",
    "    f, ax = plt.subplots(2,1,figsize=(20,10))\n",
    "    ax[0].plot(raw_data); ax[0].set_title(\"time series\")\n",
    "    ax[1].plot(score,\"r\"); ax[1].set_title(\"change score\")\n",
    "    x_grid, y_grid = np.meshgrid(np.arange(len(score)),np.linspace(*ax[0].get_ylim()))\n",
    "    z_grid = (score/np.max(score))[x_grid]\n",
    "    ax[0].contourf(x_grid, y_grid, z_grid,alpha=0.5, cmap=\"BuPu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "time_series = np.loadtxt(\"DJ_block2_layer1_hole1_torque.csv\", delimiter=\",\", dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardcode variables \n",
    "window_length = 150\n",
    "n_windows = window_length//2\n",
    "rank = 5\n",
    "scale = True\n",
    "random_rank = min(rank + 10, window_length, n_windows)\n",
    "lag = n_windows\n",
    "scoring_step = 1\n",
    "parallel = False\n",
    "use_fast_hankel = False\n",
    "method = 'fbrsvd'\n",
    "threads = os.cpu_count()//2\n",
    "hankel_function = lg.compile_hankel\n",
    "\n",
    "\n",
    "# check the dimensions of the input array\n",
    "\n",
    "assert time_series.ndim == 1, \"Time series needs to be an 1D array.\"\n",
    "\n",
    "# check that we have at least two windows\n",
    "\n",
    "assert time_series.shape[0] > window_length, 'Time series needs to be longer than window length.'\n",
    "\n",
    "# compute the starting point of the scoring (past and future hankel need to fit)\n",
    "starting_point = window_length + n_windows + lag\n",
    "assert starting_point < time_series.shape[0], \"The time series is too short to score any points.\"\n",
    "\n",
    "# for when \"online\"\n",
    "# for x in time_series:\n",
    "\n",
    "# initialize a scoring array with no values yet\n",
    "score = np.zeros_like(time_series)\n",
    "\n",
    "# compute the offset\n",
    "offset = (n_windows + lag)\n",
    "\n",
    "for idx in range(starting_point, time_series.shape[0], scoring_step):\n",
    "\n",
    "    # compile the past hankel matrix (H1)\n",
    "    hankel_past = hankel_function(time_series, idx - lag, window_length, n_windows)\n",
    "\n",
    "    # compile the future hankel matrix (H2)\n",
    "    hankel_future = hankel_function(time_series, idx, window_length, n_windows)\n",
    "\n",
    "    # compute the score and save the returned feedback vector\n",
    "    score[idx-offset-scoring_step//2:idx-offset+(scoring_step+1)//2] = \\\n",
    "         left_entropy(np.concatenate((hankel_past, hankel_future), axis=1), rank, random_rank, method, threads)\n",
    "\n",
    "# next steps, have it print values \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x = 400\n",
    "# while x < len(time_series):\n",
    "#     # print(\"time series shape\",time_series[x-x:x].shape[0])\n",
    "#     # print(\"window length\",detector.window_length)\n",
    "#     # print(\"starting point\", detector.window_length + detector.n_windows + detector.lag)\n",
    "#     score = transform(time_series[x-x:x])\n",
    "#     plot_data_and_score(time_series[x-x:x],score)\n",
    "#     x= x+40"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
